{   "authors": ["Andrey Guzhov", "Federico Raue", "JÃ¶rn Hees", "Andreas Dengel"],
    "references": ["https://ieeexplore.ieee.org/document/9747631", "https://github.com/AndreyGuzhov/AudioCLIP"],
    "downstream_tasks": ["environmental_sounds_classification"],
    "install_cmds": ["GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/AndreyGuzhov/AudioCLIP.git",
                     "pip install librosa==0.10.2",
                     "pip install numpy==1.26.4",
                     "pip install pandas==2.2.2",
                     "pip install pytorch-ignite==0.5.1",
                     "pip install scipy==1.13.1",
                     "pip install termcolor==2.5.0",
                     "pip install torch==2.5.1",
                     "pip install torchvision==0.20.1",
                     "pip install tqdm==4.67.1",
                     "pip install visdom==0.2.4",
                     "pip install ftfy",
                     "pip install regex==2024.11.6"],
    "import_context": "./AudioCLIP/",
    "import_cmds": ["wget -O ./assets/bpe_simple_vocab_16e6.txt.gz https://github.com/AndreyGuzhov/AudioCLIP/releases/download/v0.1/bpe_simple_vocab_16e6.txt.gz",
                    "wget -O ./assets/AudioCLIP-Full-Training.pt https://github.com/AndreyGuzhov/AudioCLIP/releases/download/v0.1/AudioCLIP-Full-Training.pt",
                    "import sys",
                    "import os",
                    "sys.path.insert(0, os.getcwd())",
                    "import torch",
                    "from model import AudioCLIP"],
    "model_init": ["model = AudioCLIP(pretrained=f'./AudioCLIP/assets/AudioCLIP-Full-Training.pt')"],
    "sample_rate": 44100,
    "in_shape": 2,
    "pre_proc": ["x = x.unsqueeze(1)"],
    "embed_fwd": ["model.eval()",
                  "((y, _, _), _), _ = model(audio=x)",
                  "y = y / torch.linalg.norm(y, dim=-1, keepdim=True)"]
}