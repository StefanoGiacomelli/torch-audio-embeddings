{   "authors": ["Daisuke Niizumi", "Daiki Takeuchi", "Yasunori Ohishi", "Noboru Harada", "Kunio Kashino"],
    "references": ["https://ieeexplore.ieee.org/document/10502167", "https://github.com/nttcslab/m2d/"],
    "downstream_tasks": ["audio_representation"],
    "install_cmds": ["pip install torch==2.5.1",
                     "pip install torchaudio==2.5.1",
                     "pip install torchvision==0.20.1",
                     "pip install tensorboard",
                     "pip install fire",
                     "pip install tqdm",
                     "pip install librosa",
                     "pip install nnAudio",
                     "pip install timm==0.4.5",
                     "pip install transformers",
                     "pip install einops",
                     "pip install easydict",
                     "pip install torchlibrosa",
                     "wget https://raw.githubusercontent.com/nttcslab/m2d/master/examples/portable_m2d.py",
                     "wget https://github.com/nttcslab/m2d/releases/download/v0.1.0/m2d_clap_vit_base-80x608p16x16-240128.zip"],
    "import_cmds": ["import zipfile",
                    "with zipfile.ZipFile('m2d_clap_vit_base-80x608p16x16-240128.zip', 'r') as zip_ref: zip_ref.extractall('.')",
                    "import torch",
                    "from portable_m2d import PortableM2D"],
    "model_init": ["model = PortableM2D(weight_file='m2d_clap_vit_base-80x608p16x16-240128/checkpoint-300.pth')"],
    "sample_rate": 16000,
    "in_shape": 2,
    "embed_fwd": ["y = model(x)"]
}